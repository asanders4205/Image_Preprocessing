{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3643b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "from imutils import paths\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "print(cv2.__version__)\n",
    "\n",
    "# Image qualtiy metrics\n",
    "# https://www.mathworks.com/help/images/image-quality-metrics.html\n",
    "# https://learnopencv.com/image-quality-assessment-brisque/\n",
    "# blur with opencv https://pyimagesearch.com/2015/09/07/blur-detection-with-opencv2/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ee6b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_of_laplacian(image):\n",
    "\t# compute the Laplacian of the image and then return the focus\n",
    "\t# measure, which is simply the variance of the Laplacian\n",
    "\t# print(f'variance_of_laplacian: {cv2.Laplacian(image, cv2.CV_64F).var()}')\n",
    "\t\n",
    "\n",
    "\t# # Try to convert each individual data value to native datatype from np datatype\n",
    "\t# np_variance = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\t# native_variance = val.item(np_variance)\n",
    "\n",
    "\treturn cv2.Laplacian(image, cv2.CV_64F).var()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bdaebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define variables\"\"\"\n",
    "\"\"\" Just one image \"\"\"\n",
    "# measure, which is simply the variance of the Laplacian\n",
    "# imagePath = 'C:/Users/alecs/Documents/ML/Image_Preprocessing/data/input_images/Images_1.jpg'\n",
    "# image = cv2.imread(imagePath)\n",
    "# print(f'variance_of_laplacian: {cv2.Laplacian(image, cv2.CV_64F).var()}')\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" All images in directory \"\"\"\n",
    "directory_path = 'C:/Users/alecs/Documents/ML/Image_Preprocessing/data/input_images'\n",
    "# directory_path = 'C:/Users/alecs/Documents/ML/Image_Preprocessing/data/sample_dir'\n",
    "blurriness_ratings = [] # Holds numpy floating point objects\n",
    "blurriness_labels = [] # Holds labels binning blurriness ratings according to the threshold\n",
    "threshold = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3056a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>Blurry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>522</td>\n",
       "      <td>Not Blurry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>Blurry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>Not Blurry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278</td>\n",
       "      <td>Not Blurry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>194</td>\n",
       "      <td>Not Blurry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Not Blurry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58</td>\n",
       "      <td>Blurry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>Blurry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62</td>\n",
       "      <td>Blurry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratings      labels\n",
       "0       89      Blurry\n",
       "1      522  Not Blurry\n",
       "2       74      Blurry\n",
       "3      194  Not Blurry\n",
       "4      278  Not Blurry\n",
       "5      194  Not Blurry\n",
       "6      107  Not Blurry\n",
       "7       58      Blurry\n",
       "8       31      Blurry\n",
       "9       62      Blurry"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find laplacian variance for each image in a dataset\n",
    "for imagePath in paths.list_images(directory_path):\n",
    "    # load the image, convert it to grayscale, and compute the focus measure of the image using the Variance of Laplacian method\n",
    "    image = cv2.imread(imagePath)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fm = variance_of_laplacian(gray)\n",
    "    text = \"Not Blurry\"\n",
    "    # if the focus measure is less than the supplied threshold,\n",
    "    # then the image should be considered \"blurry\"\n",
    "    if fm < threshold:\n",
    "        text = \"Blurry\"\n",
    "\n",
    "\n",
    "    # Append text label to a List to merge into DF after processing\n",
    "    blurriness_labels.append(text)\n",
    "\n",
    "    # Append numpy ratings to a List to be processed later\n",
    "    blurriness_ratings.append(fm) \n",
    "\n",
    "\n",
    "\n",
    "# Check types\n",
    "# print(f'blurriness_ratings type: {type(blurriness_ratings)}')\n",
    "# print(f'blurriness_labels type: {type(blurriness_labels)}')\n",
    "\n",
    "\n",
    "\n",
    "# Convert array to native datatypes\n",
    "blurriness_ratings_native = [float(x) for x in blurriness_ratings]\n",
    "\n",
    "# Convert native unrounded floats to rounded floats\n",
    "blurriness_ratings_native = [round(x) for x in blurriness_ratings_native]\n",
    "\n",
    "ratings_labels = pd.DataFrame({'ratings': blurriness_ratings_native, 'labels': blurriness_labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "045caaf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (24000) does not match length of index (12000)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m input_dataframe = pd.read_csv(input_data_filename)      \u001b[38;5;66;03m# Store in DF\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# FIXME size of Lists does not match - am I not labelling all images with quality ratings?\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43minput_dataframe\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mblurriness_rating\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = blurriness_ratings_native\n\u001b[32m      7\u001b[39m input_dataframe[\u001b[33m'\u001b[39m\u001b[33mblurriness_label\u001b[39m\u001b[33m'\u001b[39m] = blurriness_labels\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alecs\\Documents\\ML\\Image_Preprocessing\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4322\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4319\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4321\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4322\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alecs\\Documents\\ML\\Image_Preprocessing\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4535\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4525\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4526\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4527\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4528\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4533\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4534\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4535\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4538\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4539\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4540\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4541\u001b[39m     ):\n\u001b[32m   4542\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4543\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alecs\\Documents\\ML\\Image_Preprocessing\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:5288\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m.index)\n\u001b[32m   5287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m-> \u001b[39m\u001b[32m5288\u001b[39m     \u001b[43mcom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5289\u001b[39m arr = sanitize_array(value, \u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   5290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5291\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[32m   5292\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m value.dtype == \u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5295\u001b[39m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[32m   5296\u001b[39m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alecs\\Documents\\ML\\Image_Preprocessing\\venv\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[39m, in \u001b[36mrequire_length_match\u001b[39m\u001b[34m(data, index)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[33;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) != \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLength of values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdoes not match length of index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Length of values (24000) does not match length of index (12000)"
     ]
    }
   ],
   "source": [
    "input_data_filename = \"../data/BIQ2021_cleaned.csv\"  # Input data - cleaned filenames, subjective quality ratings and MOS scores\n",
    "input_dataframe = pd.read_csv(input_data_filename)      # Store in DF\n",
    "\n",
    "\n",
    "# FIXME size of Lists does not match - am I not labelling all images with quality ratings?\n",
    "input_dataframe['blurriness_rating'] = blurriness_ratings_native\n",
    "input_dataframe['blurriness_label'] = blurriness_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bf875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Images</th>\n",
       "      <th>MOS</th>\n",
       "      <th>StandardDeviation</th>\n",
       "      <th>QualityRating</th>\n",
       "      <th>ratings</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Images_1.jpg</td>\n",
       "      <td>0.138205</td>\n",
       "      <td>0.054030</td>\n",
       "      <td>unusable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Images_2.jpg</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.318964</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Images_3.jpg</td>\n",
       "      <td>0.679017</td>\n",
       "      <td>0.152763</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Images_4.jpg</td>\n",
       "      <td>0.442209</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Images_5.jpg</td>\n",
       "      <td>0.484388</td>\n",
       "      <td>0.135056</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Images_6.jpg</td>\n",
       "      <td>0.309230</td>\n",
       "      <td>0.024838</td>\n",
       "      <td>unusable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Images_7.jpg</td>\n",
       "      <td>0.419692</td>\n",
       "      <td>0.043562</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Images_8.jpg</td>\n",
       "      <td>0.211867</td>\n",
       "      <td>0.045066</td>\n",
       "      <td>unusable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Images_9.jpg</td>\n",
       "      <td>0.097496</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>unusable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Images_10.jpg</td>\n",
       "      <td>0.832204</td>\n",
       "      <td>0.073618</td>\n",
       "      <td>high</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         Images       MOS  StandardDeviation QualityRating  \\\n",
       "0         0.0   Images_1.jpg  0.138205           0.054030      unusable   \n",
       "1         1.0   Images_2.jpg  0.654088           0.318964          high   \n",
       "2         2.0   Images_3.jpg  0.679017           0.152763          high   \n",
       "3         3.0   Images_4.jpg  0.442209           0.009709           low   \n",
       "4         4.0   Images_5.jpg  0.484388           0.135056           low   \n",
       "5         5.0   Images_6.jpg  0.309230           0.024838      unusable   \n",
       "6         6.0   Images_7.jpg  0.419692           0.043562           low   \n",
       "7         7.0   Images_8.jpg  0.211867           0.045066      unusable   \n",
       "8         8.0   Images_9.jpg  0.097496           0.013482      unusable   \n",
       "9         9.0  Images_10.jpg  0.832204           0.073618          high   \n",
       "\n",
       "   ratings labels  \n",
       "0      NaN    NaN  \n",
       "1      NaN    NaN  \n",
       "2      NaN    NaN  \n",
       "3      NaN    NaN  \n",
       "4      NaN    NaN  \n",
       "5      NaN    NaN  \n",
       "6      NaN    NaN  \n",
       "7      NaN    NaN  \n",
       "8      NaN    NaN  \n",
       "9      NaN    NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join quality ratings on cleaned dataset\n",
    "# Convert csv to a df, merge on quality ratings df\n",
    "# Read in BIQ2021.csv, save to DF\n",
    "# input_data_filename = \"../data/BIQ2021.csv\"  # Input data with subjective quality ratings and MOS scores\n",
    "# input_dataframe = pd.read_csv(input_data_filename)      # Store in DF\n",
    "\n",
    "\n",
    "# Merge ratings df onto BIQ2021 dataframe, save to CSV\n",
    "\n",
    "# input_dataframe\n",
    "# ratings_labels\n",
    "\n",
    "\n",
    "frames = [input_dataframe, ratings_labels]\n",
    "result = pd.concat(frames)\n",
    "\n",
    "result.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49146a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"\"\"Loop over directory, return variance for each image?\"\"\"\n",
    "# def measure_blur(directory_path): # Return a dataframe\n",
    "#     # define threshold\n",
    "#     threshold = 100.0\n",
    "    \n",
    "#     # Define series\n",
    "#     blurriness_ratings = []\n",
    "    \n",
    "#     # loop over the input images\n",
    "#     for imagePath in paths.list_images(directory_path):\n",
    "#         # load the image, convert it to grayscale, and compute the\n",
    "#         # focus measure of the image using the Variance of Laplacian\n",
    "#         # method\n",
    "#         image = cv2.imread(imagePath)\n",
    "#         gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#         fm = variance_of_laplacian(gray)\n",
    "#         text = \"Not Blurry\"\n",
    "#         # if the focus measure is less than the supplied threshold,\n",
    "#         # then the image should be considered \"blurry\"\n",
    "#         if fm < threshold:\n",
    "#             text = \"Blurry\"\n",
    "        \n",
    "#         blurriness_ratings.append(fm)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#         \"\"\"# show the image\n",
    "#         cv2.putText(image, \"{}: {:.2f}\".format(text, fm), (10, 30),\n",
    "#             cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "#         cv2.imshow(\"Image\", image)\n",
    "#         key = cv2.waitKey(0)\"\"\"\n",
    "#     # End for\n",
    "\n",
    "#     return blurriness_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9814c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging:\n",
    "\n",
    "# Verify DFs are same size\n",
    "# a=input_dataframe.shape[0]\n",
    "# b=ratings_labels.shape[0]\n",
    "# print(f'BIQ2021 dataset size: {a}')\n",
    "# print(f'ratings_labels size: {b}')\n",
    "# print(f'Dataframes equal size (T/F): {a==b}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
