{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3643b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "from imutils import paths\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "print(cv2.__version__)\n",
    "\n",
    "# Image qualtiy metrics\n",
    "# https://www.mathworks.com/help/images/image-quality-metrics.html\n",
    "# https://learnopencv.com/image-quality-assessment-brisque/\n",
    "# blur with opencv https://pyimagesearch.com/2015/09/07/blur-detection-with-opencv2/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ee6b16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_of_laplacian(image):\n",
    "\t# compute the Laplacian of the image and then return the focus\n",
    "\t# measure, which is simply the variance of the Laplacian\n",
    "\t# print(f'variance_of_laplacian: {cv2.Laplacian(image, cv2.CV_64F).var()}')\n",
    "\t\n",
    "\n",
    "\t# # Try to convert each individual data value to native datatype from np datatype\n",
    "\t# np_variance = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\t# native_variance = val.item(np_variance)\n",
    "\n",
    "\treturn cv2.Laplacian(image, cv2.CV_64F).var()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bdaebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Define variables\"\"\"\n",
    "\"\"\" Just one image \"\"\"\n",
    "# measure, which is simply the variance of the Laplacian\n",
    "# imagePath = 'C:/Users/alecs/Documents/ML/Image_Preprocessing/data/input_images/Images_1.jpg'\n",
    "# image = cv2.imread(imagePath)\n",
    "# print(f'variance_of_laplacian: {cv2.Laplacian(image, cv2.CV_64F).var()}')\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" All images in directory \"\"\"\n",
    "directory_path = 'C:/Users/alecs/Documents/ML/Image_Preprocessing/data/input_images'\n",
    "# directory_path = 'C:/Users/alecs/Documents/ML/Image_Preprocessing/data/sample_dir'\n",
    "blurriness_ratings = [] # Holds numpy floating point objects\n",
    "blurriness_labels = [] # Holds labels binning blurriness ratings according to the threshold\n",
    "threshold = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3056a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48044"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find laplacian variance for each image in a dataset\n",
    "for imagePath in paths.list_images(directory_path):\n",
    "    # load the image, convert it to grayscale, and compute the focus measure of the image using the Variance of Laplacian method\n",
    "    image = cv2.imread(imagePath)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fm = variance_of_laplacian(gray)\n",
    "    text = \"Not Blurry\"\n",
    "    # if the focus measure is less than the supplied threshold,\n",
    "    # then the image should be considered \"blurry\"\n",
    "    if fm < threshold:\n",
    "        text = \"Blurry\"\n",
    "\n",
    "\n",
    "    # Append text label to a Series to merge into DF after processing\n",
    "    blurriness_labels.append(text) # List, not Dataframe\n",
    "\n",
    "    # Append numpy ratings to a Series to be processed later\n",
    "    blurriness_ratings.append(fm) # List, not Dataframe\n",
    "\n",
    "\n",
    "\n",
    "# Check types\n",
    "# print(f'blurriness_ratings type: {type(blurriness_ratings)}')\n",
    "# print(f'blurriness_labels type: {type(blurriness_labels)}')\n",
    "\n",
    "\n",
    "\n",
    "# Convert array to native datatypes\n",
    "blurriness_ratings_native = [float(x) for x in blurriness_ratings]\n",
    "\n",
    "# Convert native unrounded floats to rounded floats\n",
    "blurriness_ratings_native = [round(x) for x in blurriness_ratings_native]\n",
    "\n",
    "# Create DF from 2 lists\n",
    "\n",
    "#  blurriness_ratings_native\n",
    "#  blurriness_labels\n",
    "ratings_labels = pd.DataFrame({'ratings': blurriness_ratings_native, 'labels': blurriness_labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "045caaf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (24022) does not match length of index (12000)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m input_data_filename = \u001b[33m\"\u001b[39m\u001b[33m../data/BIQ2021.csv\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Input data with subjective quality ratings and MOS scores\u001b[39;00m\n\u001b[32m      3\u001b[39m input_dataframe = pd.read_csv(input_data_filename)      \u001b[38;5;66;03m# Store in DF\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43minput_dataframe\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mblurriness_rating\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m = blurriness_ratings_native\n\u001b[32m      6\u001b[39m input_dataframe[\u001b[33m'\u001b[39m\u001b[33mblurriness_label\u001b[39m\u001b[33m'\u001b[39m] = blurriness_labels\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alecs\\Documents\\ML\\Image_Preprocessing\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4322\u001b[39m, in \u001b[36mDataFrame.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4319\u001b[39m     \u001b[38;5;28mself\u001b[39m._setitem_array([key], value)\n\u001b[32m   4320\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4321\u001b[39m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4322\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alecs\\Documents\\ML\\Image_Preprocessing\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4535\u001b[39m, in \u001b[36mDataFrame._set_item\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   4525\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4526\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4527\u001b[39m \u001b[33;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[32m   4528\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4533\u001b[39m \u001b[33;03m    ensure homogeneity.\u001b[39;00m\n\u001b[32m   4534\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4535\u001b[39m     value, refs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4537\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4538\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns\n\u001b[32m   4539\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n\u001b[32m   4540\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value.dtype, ExtensionDtype)\n\u001b[32m   4541\u001b[39m     ):\n\u001b[32m   4542\u001b[39m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[32m   4543\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.is_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.columns, MultiIndex):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alecs\\Documents\\ML\\Image_Preprocessing\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:5288\u001b[39m, in \u001b[36mDataFrame._sanitize_column\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m   5285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m.index)\n\u001b[32m   5287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[32m-> \u001b[39m\u001b[32m5288\u001b[39m     \u001b[43mcom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5289\u001b[39m arr = sanitize_array(value, \u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   5290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5291\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[32m   5292\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m value.dtype == \u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   5295\u001b[39m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[32m   5296\u001b[39m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alecs\\Documents\\ML\\Image_Preprocessing\\venv\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[39m, in \u001b[36mrequire_length_match\u001b[39m\u001b[34m(data, index)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[33;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) != \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLength of values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdoes not match length of index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Length of values (24022) does not match length of index (12000)"
     ]
    }
   ],
   "source": [
    "# Just add the lists to the DF?\n",
    "input_data_filename = \"../data/BIQ2021.csv\"  # Input data with subjective quality ratings and MOS scores\n",
    "input_dataframe = pd.read_csv(input_data_filename)      # Store in DF\n",
    "\n",
    "input_dataframe['blurriness_rating'] = blurriness_ratings_native\n",
    "input_dataframe['blurriness_label'] = blurriness_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd555e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24022, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA\n",
    "\n",
    "input_dataframe.shape\n",
    "\n",
    "\n",
    "# ratings_labels.shape[0] # 24,022\n",
    "# ratings_labels.shape # 24,022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bf875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIQ2021 dataset size: 12000\n",
      "ratings_labels size: 24022\n",
      "Dataframes equal size (T/F): False\n"
     ]
    }
   ],
   "source": [
    "# Join quality ratings on cleaned dataset\n",
    "# Convert csv to a df, merge on quality ratings df\n",
    "# Read in BIQ2021.csv, save to DF\n",
    "\n",
    "# input_data_filename = \"../data/BIQ2021.csv\"  # Input data with subjective quality ratings and MOS scores\n",
    "# input_dataframe = pd.read_csv(input_data_filename)      # Store in DF\n",
    "\n",
    "a=input_dataframe.shape[0]\n",
    "b=ratings_labels.shape[0]\n",
    "print(f'BIQ2021 dataset size: {a}')\n",
    "print(f'ratings_labels size: {b}')\n",
    "\n",
    "print(f'Dataframes equal size (T/F): {a==b}')\n",
    "\n",
    "\n",
    "# ensure size of df == that of the ratings df\n",
    "# If so, merge ratings df onto BIQ2021 dataframe, save to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea77ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f': {}')\n",
    "\n",
    "# Summary stats\n",
    "# df.head(10)\n",
    "\n",
    "# Not working - look into dataframe summary stats\n",
    "# df.size\n",
    "# df['ratings'].min()\n",
    "# df['ratings'].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13e0c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test above function\n",
    "directory_path = 'data/input_images'\n",
    "\n",
    "# define threshold\n",
    "threshold = 100.0\n",
    "\n",
    "# Define series\n",
    "blurriness_ratings = []\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in paths.list_images(directory_path):\n",
    "    # load the image, convert it to grayscale, and compute the\n",
    "    # focus measure of the image using the Variance of Laplacian\n",
    "    # method\n",
    "    image = cv2.imread(imagePath)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    fm = variance_of_laplacian(gray)\n",
    "    text = \"Not Blurry\"\n",
    "    # if the focus measure is less than the supplied threshold,\n",
    "    # then the image should be considered \"blurry\"\n",
    "    if fm < threshold:\n",
    "        text = \"Blurry\"\n",
    "    \n",
    "    blurriness_ratings.append(fm)\n",
    "    \n",
    "    print(f'fm: {fm}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9b50e",
   "metadata": {},
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Convert csv to df\n",
    "    df = pd.read_csv(directory_path)\n",
    "\n",
    "    # Get number of ratings\n",
    "    num_of_ratings = blurriness_ratings.size\n",
    "\n",
    "    # Make sure there's a rating for every image\n",
    "    assert df.length == num_of_ratings\n",
    "\n",
    "    # print(f'df length: {df.length}')\n",
    "\n",
    "    # print(f'num_of_ratings: {num_of_ratings}')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # src = 'data/input_images/Images_1.jpg' # sample image\n",
    "    \n",
    "    # # Read image\n",
    "    # image = cv2.imread(src)\n",
    "    # if image is None:\n",
    "    #       raise FileNotFoundError(f'Could not read image at {src}')\n",
    "    \n",
    "\n",
    "    #  # Convert the image to grayscale\n",
    "    # # src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # src_gray = cv2.imread(src,cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # cv2.imshow(\"Image\", src_gray)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96656f31",
   "metadata": {},
   "source": [
    "\n",
    "# \"\"\"Loop over directory, return variance for each image?\"\"\"\n",
    "# def measure_blur(directory_path): # Return a dataframe\n",
    "#     # define threshold\n",
    "#     threshold = 100.0\n",
    "    \n",
    "#     # Define series\n",
    "#     blurriness_ratings = []\n",
    "    \n",
    "#     # loop over the input images\n",
    "#     for imagePath in paths.list_images(directory_path):\n",
    "#         # load the image, convert it to grayscale, and compute the\n",
    "#         # focus measure of the image using the Variance of Laplacian\n",
    "#         # method\n",
    "#         image = cv2.imread(imagePath)\n",
    "#         gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#         fm = variance_of_laplacian(gray)\n",
    "#         text = \"Not Blurry\"\n",
    "#         # if the focus measure is less than the supplied threshold,\n",
    "#         # then the image should be considered \"blurry\"\n",
    "#         if fm < threshold:\n",
    "#             text = \"Blurry\"\n",
    "        \n",
    "#         blurriness_ratings.append(fm)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#         \"\"\"# show the image\n",
    "#         cv2.putText(image, \"{}: {:.2f}\".format(text, fm), (10, 30),\n",
    "#             cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "#         cv2.imshow(\"Image\", image)\n",
    "#         key = cv2.waitKey(0)\"\"\"\n",
    "#     # End for\n",
    "\n",
    "#     return blurriness_ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
